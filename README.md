# Machine Learning Project Template: 25 Industry-Based  Projects

A comprehensive collection of real-world Machine Learning projects across 25 industries for bootcamp participants.

[![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Python%203.8%2B-blue)](https://www.python.org)
[![Projects](https://img.shields.io/badge/Projects-25%20Examples-brightgreen)](example_projects/)
[![License](https://img.shields.io/badge/License-MIT-yellow)]()
[![Status](https://img.shields.io/badge/Status-Active-success)]()

---

## Repository Purpose

This repository is a **reference template** with 25 real-world, classical ML example projects across different industries and problem types. Review these projects to understand how different industry domains approach Machine Learning problems, then apply the same patterns to your own bootcamp project.

---

## 1) How to Use This Repository

1. Clone this repository locally:

   ```bash
   git clone https://github.com/username/Applied-Machine-Learning-Projects.git
   cd Applied-Machine-Learning-Projects
   ```

3. Create and activate a virtual environment:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   ```

4. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

5. Start working through notebooks in order:
   - `notebooks/01_eda.ipynb`
   - `notebooks/02_feature_engineering.ipynb`
   - `notebooks/03_modeling_evaluation.ipynb`

---

## 2) Folder Structure

```text
Applied-Machine-Learning-Projects/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini                  # Test configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original immutable source data
â”‚   â””â”€â”€ processed/              # Cleaned/transformed data for modeling
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â””â”€â”€ 03_modeling_evaluation.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py   # load â†’ clean â†’ save pipeline
â”‚   â”œâ”€â”€ feature_engineering.py  # ColumnTransformer builder
â”‚   â”œâ”€â”€ train.py                # model training & saving
â”‚   â””â”€â”€ evaluate.py             # metrics & reporting
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_data_preprocessing.py
â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â”œâ”€â”€ test_train.py
â”‚   â””â”€â”€ test_evaluate.py
â”œâ”€â”€ example_projects/           # 25 industry-based ML examples
â”‚   â””â”€â”€ <project>/
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ starter_notebook.ipynb
â”œâ”€â”€ models/                     # Saved models (*.joblib)
â””â”€â”€ reports/
    â”œâ”€â”€ figures/                # Plots and visual outputs
    â””â”€â”€ metrics/                # Evaluation summaries (JSON/CSV)
```

---

## 3) Dataset Organization Guidelines

- Put untouched source files in `data/raw/`.
- Write cleaned or engineered datasets to `data/processed/`.
- Never overwrite raw data.
- Prefer meaningful names, e.g.:
  - `data/raw/customer_churn.csv`
  - `data/processed/customer_churn_clean.csv`
- If data is sensitive, do not commit it to Git. Add patterns to `.gitignore` as needed.

Recommended workflow:

1. Load from `data/raw/`.
2. Validate schema and missing values.
3. Clean + transform â†’ save to `data/processed/`.
4. Train and evaluate from `data/processed/`.

---

## 4) Running the Pipeline

Each `src/` module can be run standalone in sequence:

```bash
python src/data_preprocessing.py   # raw â†’ data/processed/sample_clean.csv
python src/train.py                # processed CSV â†’ models/baseline_model.joblib
                                   #               + models/preprocessor.joblib
                                   #               + reports/metrics/baseline_metrics.json
python src/evaluate.py             # reload model â†’ print metrics
```

---

## 5) Running Tests

```bash
python -m pytest tests/
```

The suite covers all `src/` modules with 100% coverage (excluding CLI `__main__` blocks).

---

## :factory: Industry-Based Machine Learning Project Catalog

All 25 example projects are in `example_projects/`. Each project includes a `README.md` (problem definition, dataset, recommended models, metrics) and a `starter_notebook.ipynb` ready to run after downloading the dataset.

### A) Retail & E-commerce

| # | Project | Type |
|---|---|---|
| 10 | [Customer Satisfaction Prediction](example_projects/10_customer-satisfaction-prediction/) | Classification |
| 05 | [Sales Forecasting (Walmart)](example_projects/05_sales-forecasting/) | Time Series |
| 23 | [Store Item Demand Forecasting](example_projects/23_store-item-demand-forecasting/) | Time Series |
| 09 | [Product Recommendation (MovieLens)](example_projects/09_product-recommendation/) | Recommender System |

### B) Marketing & CRM

| # | Project | Type |
|---|---|---|
| 01 | [Customer Churn Prediction](example_projects/01_customer-churn-prediction/) | Classification |
| 13 | [Marketing Campaign Response](example_projects/13_marketing-campaign-response-prediction/) | Classification |
| 08 | [Customer Lifetime Value (CLTV)](example_projects/08_cltv-prediction/) | Regression |
| 03 | [Customer Segmentation](example_projects/03_customer-segmentation/) | Clustering |

### C) Finance & Insurance

| # | Project | Type |
|---|---|---|
| 04 | [Credit Risk Classification](example_projects/04_credit-risk-classification/) | Classification |
| 07 | [Credit Card Fraud Detection](example_projects/07_fraud-detection/) | Classification (imbalanced) |
| 15 | [Loan Default Prediction](example_projects/15_loan-default-prediction/) | Classification |
| 20 | [Insurance Cost Prediction](example_projects/20_insurance-cost-prediction/) | Regression |

### D) Energy & Utilities

| # | Project | Type |
|---|---|---|
| 14 | [Energy Consumption Forecasting](example_projects/14_time-series-energy-consumption/) | Time Series |
| 21 | [Solar Power Generation Forecasting](example_projects/21_solar-power-generation-prediction/) | Time Series |

### E) Healthcare

| # | Project | Type |
|---|---|---|
| 18 | [Diabetes Risk Prediction](example_projects/18_diabetes-prediction/) | Classification |
| 19 | [Heart Disease Prediction](example_projects/19_heart-disease-prediction/) | Classification |
| 16 | [Calorie Expenditure Prediction](example_projects/16_calorie-intake-prediction/) | Regression |

### F) HR & Workforce

| # | Project | Type |
|---|---|---|
| 06 | [Employee Attrition Prediction](example_projects/06_employee-attrition-prediction/) | Classification |

### G) Media & Entertainment

| # | Project | Type |
|---|---|---|
| 11 | [Movie Review Sentiment Analysis](example_projects/11_movie-review-sentiment-analysis/) | Text Classification |
| 12 | [Email / SMS Spam Detection](example_projects/12_email-spam-classification/) | Text Classification |
| 17 | [Podcast Listening Time Prediction](example_projects/17_podcast-listening-prediction/) | Regression |

### H) General / Cross-Industry

| # | Project | Type |
|---|---|---|
| 02 | [House Price Prediction](example_projects/02_house-price-prediction/) | Regression |
| 24 | [California Housing Price Regression](example_projects/24_california-house-price-regression/) | Regression |
| 22 | [Wine Quality Prediction](example_projects/22_wine-quality-prediction/) | Classification |
| 25 | [Binary Rainfall Prediction](example_projects/25_binary-prediction-rainfall/) | Classification |

---

## :compass: How Bootcamp Participants Should Use This Repository

- Choose **ONE example project** from `example_projects/` that interests you.
- Review its `README.md` for problem definition, dataset recommendations, and baseline approaches.
- Study the `starter_notebook.ipynb` to understand the workflow and methodology.
- Create your own project by applying the same patterns to a dataset of your choice.
- Build your own dataset-driven solution and document your decisions clearly.

---

## :white_check_mark: Expectations for Bootcamp Projects

Your final project should include:

- A clear problem definition
- Exploratory Data Analysis (EDA)
- Feature engineering
- At least two models for comparison
- Proper evaluation metrics aligned with the problem type
- Business / real-world interpretation of the results

---

## 6) Workflow Sections

### EDA

Goal: understand distributions, missingness, class balance, outliers, and relationships.

Checklist:

- Inspect shape, dtypes, null counts.
- Plot target distribution and key feature distributions.
- Note hypotheses and potential data quality issues.

### Feature Engineering

Goal: build model-ready inputs.

Checklist:

- Define numeric/categorical/boolean feature groups.
- Handle missing values (median for numeric, mode for categorical).
- Encode categorical features with `OneHotEncoder`.
- Scale numeric features where appropriate.

### Modeling

Goal: train baseline and improved models.

Checklist:

- Create train/test split (`stratify=y` for classification).
- Wrap preprocessing + model in a `sklearn.Pipeline`.
- Track parameters and random seeds for reproducibility.

### Evaluation

Goal: quantify model quality and compare alternatives.

Checklist:

- Select proper metrics: ROC-AUC / F1 (classification), MAE / RMSE / RÂ² (regression), MAPE (time series).
- For imbalanced datasets, prefer Recall, F1, and PR-AUC over Accuracy.
- Save metrics to `reports/metrics/`.

### Conclusion

Goal: communicate findings and next steps.

Checklist:

- Summarize best-performing model and key metric.
- Highlight limitations and assumptions.
- Suggest concrete improvements (hyperparameter tuning, more data, feature ideas).

---

## 7) Example Snippets

### Loading and Cleaning Data

```python
# Using the src/ module directly:
from src.data_preprocessing import load_raw_data, clean_data, save_processed_data

df = load_raw_data("data/raw/your_dataset.csv")  # also supports .xlsx, .json, .parquet
df = clean_data(df)
save_processed_data(df, "data/processed/clean_dataset.csv")
```

### Training a Classification Model

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

# Import src/ module
import sys; sys.path.insert(0, "src")
from feature_engineering import build_preprocessor

df = pd.read_csv("data/processed/clean_dataset.csv")
TARGET = "target"  # replace with your column name

X = df.drop(columns=[TARGET])
y = df[TARGET]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

model = Pipeline([
    ("preprocessor", build_preprocessor(X_train)),
    ("clf", LogisticRegression(max_iter=1000, class_weight="balanced")),
])
model.fit(X_train, y_train)
```

### Evaluation

```python
from sklearn.metrics import classification_report, roc_auc_score

preds = model.predict(X_test)
probs = model.predict_proba(X_test)

# Binary
roc_auc = roc_auc_score(y_test, probs[:, 1])

# Multiclass
# roc_auc = roc_auc_score(y_test, probs, multi_class="ovr", average="macro")

print(f"ROC-AUC: {roc_auc:.4f}")
print(classification_report(y_test, preds))
```

### Saving a Trained Model

```python
import joblib

joblib.dump(model, "models/baseline_model.joblib")

# Reload later:
# loaded = joblib.load("models/baseline_model.joblib")
```

---

## 8) Suggested Next Steps for Learners

- Pick an example project and study its structure.
- Download the recommended dataset for that project.
- Create your own implementation following the same workflow.
- Document your results and findings in `reports/`.
- Compare your approach with the starter notebook.

Happy learning and building ðŸš€
